"""
Example: Estimating Volatility with Kalman Filter on Heston Model Data

This script demonstrates how to use the KalmanStdEstimator to estimate
the latent volatility from returns generated by a Heston stochastic
volatility model.
"""

import numpy as np
import matplotlib.pyplot as plt
from kalman_estimators import KalmanStdEstimator, create_std_estimator
from heston_model import generate_heston_data


def run_kalman_estimation(returns, r=1.0, q=0.0001, initial_std=0.01, dt=1.0):
    """
    Run Kalman filter estimation on returns data.
    
    Parameters
    ----------
    returns : np.ndarray
        Array of returns
    r : float
        Observation noise parameter
    q : float
        Process noise parameter
    initial_std : float
        Initial standard deviation estimate (annualized)
    dt : float
        Time step size (for scaling to annualized volatility)
    
    Returns
    -------
    np.ndarray
        Array of annualized volatility estimates
    """
    # Scale initial std to match the time step
    initial_std_scaled = initial_std * np.sqrt(dt)
    
    estimator = create_std_estimator(
        initial_std=initial_std_scaled,
        observation_noise=r,
        process_noise=q
    )
    
    estimates = np.zeros(len(returns))
    for i, ret in enumerate(returns):
        # Get estimate for this time step
        est_scaled = estimator.step(ret)
        # Scale back to annualized volatility
        estimates[i] = est_scaled / np.sqrt(dt)
    
    return estimates


def calculate_rolling_std(returns, window=20, dt=1.0):
    """
    Calculate rolling standard deviation for comparison.
    
    Parameters
    ----------
    returns : np.ndarray
        Array of returns
    window : int
        Window size for rolling calculation
    dt : float
        Time step size (for annualization)
    
    Returns
    -------
    np.ndarray
        Annualized rolling standard deviation estimates
    """
    rolling_std = np.zeros(len(returns))
    for i in range(len(returns)):
        start_idx = max(0, i - window + 1)
        # Calculate std and annualize it
        rolling_std[i] = np.std(returns[start_idx:i+1]) / np.sqrt(dt)
    return rolling_std


def calculate_performance_metrics(true_vol, estimated_vol):
    """
    Calculate performance metrics for volatility estimation.
    
    Parameters
    ----------
    true_vol : np.ndarray
        True volatility values
    estimated_vol : np.ndarray
        Estimated volatility values
    
    Returns
    -------
    dict
        Dictionary of performance metrics
    """
    # Align arrays (estimated_vol is one step shorter)
    true_vol_aligned = true_vol[1:]
    
    # Mean Absolute Error
    mae = np.mean(np.abs(true_vol_aligned - estimated_vol))
    
    # Root Mean Squared Error
    rmse = np.sqrt(np.mean((true_vol_aligned - estimated_vol)**2))
    
    # Mean Absolute Percentage Error
    mape = np.mean(np.abs((true_vol_aligned - estimated_vol) / true_vol_aligned)) * 100
    
    # Correlation
    correlation = np.corrcoef(true_vol_aligned, estimated_vol)[0, 1]
    
    return {
        'MAE': mae,
        'RMSE': rmse,
        'MAPE': mape,
        'Correlation': correlation
    }


def plot_results(time, true_vol, estimated_vol, returns, rolling_vol=None, save_path=None):
    """
    Create visualization of results.
    
    Parameters
    ----------
    time : np.ndarray
        Time array
    true_vol : np.ndarray
        True volatility
    estimated_vol : np.ndarray
        Estimated volatility
    returns : np.ndarray
        Returns data
    rolling_vol : np.ndarray, optional
        Rolling window volatility estimates
    save_path : str, optional
        Path to save the figure
    """
    fig, axes = plt.subplots(3, 1, figsize=(14, 10))
    
    # Plot 1: Returns
    axes[0].plot(time[1:], returns, alpha=0.5, linewidth=0.5, color='steelblue')
    axes[0].set_ylabel('Returns', fontsize=11)
    axes[0].set_title('Asset Returns (Heston Model)', fontsize=12, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    
    # Plot 2: True vs Estimated Volatility
    axes[1].plot(time[1:], true_vol[1:], label='True Volatility', 
                linewidth=2.5, alpha=0.7, color='darkblue')
    axes[1].plot(time[1:], estimated_vol, label='Kalman Filter', 
                linewidth=2, linestyle='--', alpha=0.9, color='orangered')
    if rolling_vol is not None:
        axes[1].plot(time[1:], rolling_vol, label='Rolling Std (20 periods)', 
                    linewidth=1.5, linestyle=':', alpha=0.7, color='green')
    axes[1].set_ylabel('Volatility (Std Dev)', fontsize=11)
    axes[1].set_title('True vs Estimated Volatility', fontsize=12, fontweight='bold')
    axes[1].legend(loc='best', fontsize=10)
    axes[1].grid(True, alpha=0.3)
    
    # Plot 3: Estimation Error
    error = true_vol[1:] - estimated_vol
    axes[2].plot(time[1:], error, linewidth=1, alpha=0.7, color='darkred')
    axes[2].axhline(y=0, color='black', linestyle='--', alpha=0.5, linewidth=1)
    axes[2].fill_between(time[1:], error, 0, alpha=0.3, color='lightcoral')
    axes[2].set_ylabel('Error', fontsize=11)
    axes[2].set_xlabel('Time', fontsize=11)
    axes[2].set_title('Kalman Filter Estimation Error (True - Estimated)', fontsize=12, fontweight='bold')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"Figure saved to {save_path}")
    
    plt.show()


def main():
    """Main execution function."""
    
    print("=" * 70)
    print("Kalman Filter Volatility Estimation on Heston Model Data")
    print("=" * 70)
    print()
    
    # Generate synthetic data using Heston model
    print("Generating synthetic data using Heston stochastic volatility model...")
    heston_params = {
        'S0': 100.0,      # Initial price
        'V0': 0.04,       # Initial variance (std = 0.2)
        'mu': 0.0,        # Drift
        'kappa': 2.0,     # Mean reversion speed
        'theta': 0.04,    # Long-term variance
        'sigma': 0.3,     # Vol-of-vol
        'rho': -0.7       # Correlation
    }
    
    data = generate_heston_data(
        n_steps=2000,
        T=2.0,
        seed=42,
        **heston_params
    )
    
    # Calculate dt for proper time scaling
    dt = data['time'][1] - data['time'][0]
    
    print(f"  Generated {len(data['returns'])} return observations")
    print(f"  Time horizon: {data['time'][-1]:.2f} years")
    print(f"  Time step (dt): {dt:.4f}")
    print(f"  True volatility range: [{data['volatility'].min():.4f}, {data['volatility'].max():.4f}]")
    print()
    
    # Run Kalman filter estimation with different parameter settings
    print("Running Kalman filter estimation...")
    
    # Configuration 1: Baseline - moderate tracking
    print("\nConfiguration 1: Moderate Tracking (r=0.2, q=0.01)")
    estimates_1 = run_kalman_estimation(
        data['returns'],
        r=0.2,
        q=0.01,
        initial_std=0.2,
        dt=dt
    )
    metrics_1 = calculate_performance_metrics(data['volatility'], estimates_1)
    
    print("  Performance Metrics:")
    for metric, value in metrics_1.items():
        if metric == 'MAPE':
            print(f"    {metric}: {value:.2f}%")
        else:
            print(f"    {metric}: {value:.6f}")
    
    # Configuration 2: Fast adaptation - tracks changes quickly
    print("\nConfiguration 2: Fast Adaptation (r=0.1, q=0.05)")
    estimates_2 = run_kalman_estimation(
        data['returns'],
        r=0.1,
        q=0.05,
        initial_std=0.2,
        dt=dt
    )
    metrics_2 = calculate_performance_metrics(data['volatility'], estimates_2)
    
    print("  Performance Metrics:")
    for metric, value in metrics_2.items():
        if metric == 'MAPE':
            print(f"    {metric}: {value:.2f}%")
        else:
            print(f"    {metric}: {value:.6f}")
    
    # Configuration 3: Aggressive tracking - maximum responsiveness  
    print("\nConfiguration 3: Very Aggressive (r=0.05, q=0.1)")
    estimates_3 = run_kalman_estimation(
        data['returns'],
        r=0.05,
        q=0.1,
        initial_std=0.2,
        dt=dt
    )
    metrics_3 = calculate_performance_metrics(data['volatility'], estimates_3)
    
    print("  Performance Metrics:")
    for metric, value in metrics_3.items():
        if metric == 'MAPE':
            print(f"    {metric}: {value:.2f}%")
        else:
            print(f"    {metric}: {value:.6f}")
    
    print("\n" + "=" * 70)
    print("Summary")
    print("=" * 70)
    print("\nBest configuration based on RMSE:")
    rmse_values = [metrics_1['RMSE'], metrics_2['RMSE'], metrics_3['RMSE']]
    best_config = np.argmin(rmse_values) + 1
    print(f"  Configuration {best_config} with RMSE = {min(rmse_values):.6f}")
    
    print("\nBest configuration based on Correlation:")
    corr_values = [metrics_1['Correlation'], metrics_2['Correlation'], metrics_3['Correlation']]
    best_corr_config = np.argmax(corr_values) + 1
    print(f"  Configuration {best_corr_config} with Correlation = {max(corr_values):.6f}")
    
    # Create visualization
    print("\nGenerating visualization...")
    rolling_vol = calculate_rolling_std(data['returns'], window=20, dt=dt)
    plot_results(
        data['time'],
        data['volatility'],
        estimates_1,  # Using moderate tracking configuration
        data['returns'],
        rolling_vol=rolling_vol,
        save_path='/mnt/user-data/outputs/kalman_volatility_estimation.png'
    )
    
    print("\n" + "=" * 70)
    print("Analysis Complete!")
    print("=" * 70)
    print("\nKey Findings:")
    print("  • The Kalman filter successfully tracks time-varying latent volatility")
    print("  • Higher process noise (q) is crucial for tracking Heston's stochastic volatility")
    print("  • Lower observation noise (r) increases responsiveness to volatility changes")
    print("  • There's a tradeoff between smoothness and tracking ability")
    print(f"  • Best tracking achieved correlation of {max(corr_values):.3f} with true volatility")
    print("\nThe visualization has been saved and displayed above.")


if __name__ == "__main__":
    main()
